<html>
  <head>
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <script src="https://unpkg.com/aframe-state-component@6.8.0/dist/aframe-state-component.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/socket.io-client@2/dist/socket.io.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>

    <script>
      AFRAME.registerComponent('a-face', {
        init: function () {
          // Code here.
          console.log(this.el)
        },
        tick: function () {
          const annotations = this.el.getAttribute('annotations')
          this.el.position = annotations.midwayBetweenEyes[0]
          this.el.rotation = annotations.tilt
        },
      })
    </script>
  </head>
  <body>
    <a-scene stats>
      <a-assets>
        <a-asset-item id="room" src="cineroom.gltf"></a-asset-item>
      </a-assets>
      <a-entity
        gltf-model="#room"
        position="0 0 -2"
        rotation="0 90 0"
        scale="0.2 0.2 0.2"
      ></a-entity>
      <a-video
        src="#video"
        width="10"
        height="6"
        position="-0.5 4.5 -7.5"
      ></a-video>
      <a-sky color="#aabbcc"></a-sky>
    </a-scene>
    
    
    <video
      id="video"
      height="200"
      width="200"
      style="position: fixed; bottom: 0; right: 0;"
      autoPlay
      muted
    ></video>

    <script>
      const socket = io(':8000')
      const scene = document.querySelector('a-scene')

      const timeout = (ms) => new Promise((resolve) => setTimeout(resolve, ms))

      const pick = (obj, keys) =>
        keys
          .map((k) => (k in obj ? { [k]: obj[k] } : {}))
          .reduce((res, o) => Object.assign(res, o), {})

      const calculateTilt = ({ annotations }) => {
        const dX = annotations.rightCheek[0][0] - annotations.leftCheek[0][0]
        const dY = annotations.rightCheek[0][1] - annotations.leftCheek[0][1]
        // const dZ = annotations.rightCheek[0][2] - annotations.leftCheek[0][2]
        const degree = Math.atan(dY / dX) * 180
        return degree
      }

      const calculatePosition = ({annotations}) => {
        const [x, y, z] = annotations.midwayBetweenEyes[0].map(p => p / 1000)
        return {x, y: -y, z}
      }

      const detectFace = async (model, video, emitFace) => {
        const faces = await Promise.race([
          model.estimateFaces(video),
          timeout(500)
        ])

        faces && faces.forEach((face, i) => {
          const strippedFace = {
            id: i,
            position: calculatePosition(face),
            tilt: calculateTilt(face),
          }
          emitFace(strippedFace)
        })

        return detectFace(model, video, emitFace)
      }

      async function main() {
        const video = document.querySelector('video')
        await tf.ready()
        const model = await facemesh.load()

        detectFace(model, video, (face) => {
          socket.emit('face', face)
        })
      }

      socket.on('faces', (faces) => {
        if (!AFRAME.scenes.length) {
          return
        }

        faces.forEach((face, i) => {
          let faceEl = document.getElementById(`face-${i}`)

          if (!faceEl) {
            faceEl = document.createElement('a-box')
            console.log('create')
            faceEl.setAttribute('position', '0 0 -4')
            faceEl.setAttribute('material', 'src: minecraft.png; repeat: 1 1')
            faceEl.setAttribute('a-face')
            faceEl.setAttribute('scale', '0.8 0.8')
            faceEl.setAttribute('id', `face-${i}`)

            scene.appendChild(faceEl)
          }
          faceEl.setAttribute('rotation', `0 ${face.tilt} 0`)
          faceEl.setAttribute('position', face.position)
          faceEl.object3D.position.y += 1.5
          faceEl.object3D.position.x += i
        })
      })

      const startStream = async (video) => {
        try {
          const video = document.querySelector('video')
          const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user' },
          })

          if (!stream) {
            throw new Error('You need to allow video to use this service.')
          }

          video.srcObject = stream
          video.onloadeddata = () => {
            main()
          }
        } catch (err) {
          alert(
            'Sorry. You need to use Google Chrome or Firefox to use this. ' +
              err.message
          )
        }
      }

      startStream()
    </script>
  </body>
</html>
